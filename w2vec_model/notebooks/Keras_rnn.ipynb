{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset but only keep the top n words, zero the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from matplotlib import pyplot as plt\n",
    "# from dna2vec.multi_k_model import MultiKModel\n",
    "# import seaborn as sns\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Read fasta ####\n",
    "def read_FASTA(file_name):\n",
    "    with open(file_name, \"r\") as fn:\n",
    "        text = fn.read().split(\">\")\n",
    "    text = [x.split(\"\\n\") for x in text if x != \"\"]\n",
    "    text = [[x[0],\"\".join(x[1:]).upper()] for x in text]\n",
    "    text_dict = {line[0].split('|')[0]:line[1] for line in text}\n",
    "    return text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filepath = 'pretrained/dna2vec-20161219-0153-k3to8-100d-10c-29320Mbp-sliding-Xat.w2v'\n",
    "# mk_model = MultiKModel(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(mk_model.vector(\"AAATGGTT\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "code = read_FASTA(\"../../data/train_fasta_gencode.fasta\")\n",
    "noncode = read_FASTA(\"../../data/train_fasta_lncPedia.fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_vec(seq, kmer=8, max_length=13000):\n",
    "    vectors = []\n",
    "    i = 0\n",
    "    while (i<(len(seq)-kmer)) and (i<max_length):\n",
    "        tmp = seq[i:i+kmer]\n",
    "        if 'N' in tmp:\n",
    "            i+=1\n",
    "            continue\n",
    "        vec_tmp = mk_model.vector(tmp)\n",
    "        vectors.append(vec_tmp)\n",
    "        i+=1\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cheskidova/py3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 7000\n",
    "y = np.array([1]*N + [0]*N)\n",
    "X_tmp = deepcopy(list(code.items())[:N])\n",
    "X_tmp.extend(list(noncode.items())[:N])\n",
    "len(X_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/FINAL_DATA_1/embedding_matrix.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f642096e6507>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../data/FINAL_DATA_1/embedding_matrix.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/py3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1401\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1403\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py3/lib/python3.5/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1569\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m   1570\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m                                      compression=self.compression)\n\u001b[0m\u001b[1;32m   1572\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py3/lib/python3.5/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;31m# Python 3 and no explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/FINAL_DATA_1/embedding_matrix.csv'"
     ]
    }
   ],
   "source": [
    "embedding_matrix.to_csv(\"../../data/FINAL_DATA_1/embedding_matrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_mer = 8\n",
    "embedding_matrix = dict()\n",
    "\"\"\"\n",
    "A -- 1\n",
    "T -- 2\n",
    "G -- 3\n",
    "C -- 4\n",
    "\n",
    "\"\"\"\n",
    "for i1 in \"ATGC\":\n",
    "    for i2 in \"ATGC\":\n",
    "        for i3 in \"ATGC\":\n",
    "            for i4 in \"ATGC\":\n",
    "                for i5 in \"ATGC\":\n",
    "                    for i6 in \"ATGC\":\n",
    "                        for i7 in \"ATGC\":\n",
    "                            for i8 in \"ATGC\":\n",
    "                                name = i1+i2+i3+i4+i5+i6+i7+i8\n",
    "                                embedding_matrix[name] = mk_model.vector(name)\n",
    "\n",
    "embedding_matrix['0'] = np.zeros((100,))\n",
    "embedding_matrix = pd.DataFrame(embedding_matrix).T\n",
    "embedding_matrix.insert(0,'code', range(0, len(embedding_matrix)))\n",
    "print(embedding_matrix.shape)\n",
    "embedding_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAAAAAA</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.365117</td>\n",
       "      <td>0.408025</td>\n",
       "      <td>0.064311</td>\n",
       "      <td>-0.293642</td>\n",
       "      <td>0.103023</td>\n",
       "      <td>0.089713</td>\n",
       "      <td>-0.764232</td>\n",
       "      <td>-0.003985</td>\n",
       "      <td>0.107479</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216967</td>\n",
       "      <td>-0.809641</td>\n",
       "      <td>0.370482</td>\n",
       "      <td>0.632726</td>\n",
       "      <td>0.690164</td>\n",
       "      <td>-0.406542</td>\n",
       "      <td>0.187238</td>\n",
       "      <td>-0.626230</td>\n",
       "      <td>-0.271666</td>\n",
       "      <td>0.082561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAAAAAC</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.345430</td>\n",
       "      <td>0.288133</td>\n",
       "      <td>0.324433</td>\n",
       "      <td>-0.366527</td>\n",
       "      <td>-0.170981</td>\n",
       "      <td>-0.025718</td>\n",
       "      <td>-0.380066</td>\n",
       "      <td>0.055025</td>\n",
       "      <td>-0.016809</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.233300</td>\n",
       "      <td>-0.737088</td>\n",
       "      <td>0.072006</td>\n",
       "      <td>0.639653</td>\n",
       "      <td>0.292097</td>\n",
       "      <td>-0.500181</td>\n",
       "      <td>0.094142</td>\n",
       "      <td>0.100279</td>\n",
       "      <td>-0.439565</td>\n",
       "      <td>0.160597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAAAAAG</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.310706</td>\n",
       "      <td>-0.153957</td>\n",
       "      <td>-0.397525</td>\n",
       "      <td>0.163247</td>\n",
       "      <td>0.102393</td>\n",
       "      <td>-0.393191</td>\n",
       "      <td>-0.149867</td>\n",
       "      <td>0.093688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132578</td>\n",
       "      <td>-0.596084</td>\n",
       "      <td>0.520723</td>\n",
       "      <td>0.664362</td>\n",
       "      <td>0.738464</td>\n",
       "      <td>-0.411244</td>\n",
       "      <td>-0.110038</td>\n",
       "      <td>-0.386498</td>\n",
       "      <td>-0.017523</td>\n",
       "      <td>-0.151797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAAAAAT</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.276156</td>\n",
       "      <td>0.117486</td>\n",
       "      <td>0.097248</td>\n",
       "      <td>-0.301252</td>\n",
       "      <td>-0.194590</td>\n",
       "      <td>-0.149558</td>\n",
       "      <td>-0.705774</td>\n",
       "      <td>-0.121932</td>\n",
       "      <td>0.032583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>-0.890366</td>\n",
       "      <td>0.143492</td>\n",
       "      <td>0.220740</td>\n",
       "      <td>0.490493</td>\n",
       "      <td>0.093366</td>\n",
       "      <td>-0.143799</td>\n",
       "      <td>-0.783927</td>\n",
       "      <td>-0.192266</td>\n",
       "      <td>0.223240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          code         0         1         2         3         4         5  \\\n",
       "0            0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "AAAAAAAA     1 -0.365117  0.408025  0.064311 -0.293642  0.103023  0.089713   \n",
       "AAAAAAAC     2 -0.345430  0.288133  0.324433 -0.366527 -0.170981 -0.025718   \n",
       "AAAAAAAG     3  0.000498  0.310706 -0.153957 -0.397525  0.163247  0.102393   \n",
       "AAAAAAAT     4 -0.276156  0.117486  0.097248 -0.301252 -0.194590 -0.149558   \n",
       "\n",
       "                 6         7         8    ...           90        91  \\\n",
       "0         0.000000  0.000000  0.000000    ...     0.000000  0.000000   \n",
       "AAAAAAAA -0.764232 -0.003985  0.107479    ...    -0.216967 -0.809641   \n",
       "AAAAAAAC -0.380066  0.055025 -0.016809    ...    -0.233300 -0.737088   \n",
       "AAAAAAAG -0.393191 -0.149867  0.093688    ...    -0.132578 -0.596084   \n",
       "AAAAAAAT -0.705774 -0.121932  0.032583    ...     0.003845 -0.890366   \n",
       "\n",
       "                92        93        94        95        96        97  \\\n",
       "0         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "AAAAAAAA  0.370482  0.632726  0.690164 -0.406542  0.187238 -0.626230   \n",
       "AAAAAAAC  0.072006  0.639653  0.292097 -0.500181  0.094142  0.100279   \n",
       "AAAAAAAG  0.520723  0.664362  0.738464 -0.411244 -0.110038 -0.386498   \n",
       "AAAAAAAT  0.143492  0.220740  0.490493  0.093366 -0.143799 -0.783927   \n",
       "\n",
       "                98        99  \n",
       "0         0.000000  0.000000  \n",
       "AAAAAAAA -0.271666  0.082561  \n",
       "AAAAAAAC -0.439565  0.160597  \n",
       "AAAAAAAG -0.017523 -0.151797  \n",
       "AAAAAAAT -0.192266  0.223240  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = pd.read_csv(\"../../data/embedding_matrix.csv\", index_col=0)\n",
    "embedding_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_dict = dict(zip(embedding_matrix.index, embedding_matrix.code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_kmers(seq, kmer=8, max_length=7000):\n",
    "    res = np.zeros((max_length))\n",
    "    i=0\n",
    "    while (i<(len(seq)-kmer)) and (i<max_length):\n",
    "        tmp = seq[i:i+kmer]\n",
    "        if 'N' in tmp:\n",
    "            i+=1\n",
    "            continue\n",
    "        res[i] = encoder_dict[tmp]\n",
    "        i+=1\n",
    "\n",
    "    return res\n",
    "X = np.array([np.array(make_kmers(v), dtype=np.int32) for k,v in X_tmp])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix.index = embedding_matrix.code\n",
    "embedding_matrix.drop('code', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "MAX_SEQUENCE_LENGTH = 7000\n",
    "EMBEDDING_DIM = 100\n",
    "embedding_layer = Embedding(len(embedding_matrix),\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[np.array(embedding_matrix)],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (9380, 7000)\n",
      "test:  (4620, 7000)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 7000, 100)         6553700   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 7000, 100)         400       \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 6996, 256)         128256    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 6996, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 6992, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 6992, 128)         512       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_8 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 6,847,989\n",
      "Trainable params: 293,321\n",
      "Non-trainable params: 6,554,668\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 9380 samples, validate on 4620 samples\n",
      "Epoch 1/10\n",
      "9380/9380 [==============================] - 54s - loss: 0.4843 - acc: 0.7760 - val_loss: 0.5153 - val_acc: 0.7268\n",
      "Epoch 2/10\n",
      "9380/9380 [==============================] - 54s - loss: 0.4377 - acc: 0.8018 - val_loss: 0.4388 - val_acc: 0.8182\n",
      "Epoch 3/10\n",
      "9380/9380 [==============================] - 54s - loss: 0.4122 - acc: 0.8193 - val_loss: 0.5112 - val_acc: 0.7348\n",
      "Epoch 4/10\n",
      "9380/9380 [==============================] - 54s - loss: 0.3957 - acc: 0.8217 - val_loss: 0.3951 - val_acc: 0.8104\n",
      "Epoch 5/10\n",
      "9380/9380 [==============================] - 54s - loss: 0.3717 - acc: 0.8389 - val_loss: 0.4095 - val_acc: 0.8063\n",
      "Epoch 6/10\n",
      "9380/9380 [==============================] - 54s - loss: 0.3674 - acc: 0.8365 - val_loss: 0.5237 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "9380/9380 [==============================] - 54s - loss: 0.3504 - acc: 0.8493 - val_loss: 0.3766 - val_acc: 0.8364\n",
      "Epoch 8/10\n",
      "9380/9380 [==============================] - 54s - loss: 0.3350 - acc: 0.8583 - val_loss: 0.3574 - val_acc: 0.8481\n",
      "Epoch 9/10\n",
      "9380/9380 [==============================] - 54s - loss: 0.2937 - acc: 0.8816 - val_loss: 0.4556 - val_acc: 0.7920\n",
      "Epoch 10/10\n",
      "9380/9380 [==============================] - 54s - loss: 0.2760 - acc: 0.8900 - val_loss: 0.5088 - val_acc: 0.8093\n",
      "Accuracy: 80.93%\n"
     ]
    }
   ],
   "source": [
    "# y_train_dumm = np.array(pd.get_dummies(y_train))\n",
    "# y_test_dumm = np.array(pd.get_dummies(y_test))\n",
    "\n",
    "print(\"train: \", X_train.shape)\n",
    "print(\"test: \", X_test.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=256, kernel_size=5, padding='valid', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=128, kernel_size=5, padding='valid', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "# model.add(LSTM(128)) #,dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=30, validation_data=(X_test, y_test)) #class_weight=Counter(y_train))\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# specs test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_fasta = read_FASTA(\"../../data/specs_4.0.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = np.array([np.array(make_kmers(v), dtype=np.int32) for k,v in test_fasta.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_names = np.array([k for k,v in test_fasta.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b5fb10b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../../data/pred_res.txt\", 'w') as fs:\n",
    "    for n, score in zip(test_names[pred>0.5], pred[pred>0.5]):\n",
    "        fs.write(n+'\\t'+str(score)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# Headline input: meant to receive sequences of 100 integers, between 1 and 10000.\n",
    "# Note that we can name any layer by passing it a \"name\" argument.\n",
    "main_input = Input(shape=(100,), dtype='int32', name='main_input')\n",
    "\n",
    "# This embedding layer will encode the input sequence\n",
    "# into a sequence of dense 512-dimensional vectors.\n",
    "x = Embedding(output_dim=512, input_dim=7000, input_length=100)(main_input)\n",
    "\n",
    "# A LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "lstm_out = LSTM(32)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('conv_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
